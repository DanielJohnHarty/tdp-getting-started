---
- hosts: localhost
  vars:
  - realm: TDP
  - kadmin_principal: admin/admin
  - kadmin_password: admin
  tasks:
    - name: Check ranger binary exists
      stat:
        path: files/ranger-2.0.1-TDP-0.1.0-SNAPSHOT-admin.tar.gz
      register: rg_exists
      failed_when: not rg_exists.stat.exists

- hosts: postgresql
  become: yes
  vars:
    postgresql_databases:
      - name: ranger
  tasks:
    - import_role:
        name: roles/ansible-role-postgresql
      ignore_errors: true
      tags: pg

    - name: Give postgres db user a password
      become_user: postgres
      shell: psql -c "ALTER ROLE postgres WITH PASSWORD 'postgres';"
      tags: pgpw

    - name: Create ranger database if it doesn't exist already
      become_user: postgres
      shell: if [[ -z `psql -Atqc '\list ranger' postgres` ]]; then createdb ranger; fi
      tags: pgpw2

    - name: Open listen addresses
      become_user: postgres
      shell: sed -i "s/#listen_addresses = 'localhost'/listen_addresses = '*'"/ /var/lib/pgsql/data/postgresql.conf
      tags: oip

    - name: Trust connections from master ips (add to pg_hba.conf)
      become_user: postgres
      shell: cat /etc/hosts | grep master- | grep -v 0.0.0.0 | \
             awk '{print "host all all "$1"/32   trust\nhost all all "$2"   trust\n"}' >> /var/lib/pgsql/data/pg_hba.conf

    - name: Restart postgresql service
      become: yes
      ansible.builtin.service:
        name: postgresql
        state: restarted

- hosts: ranger_admin
  become: yes
  tasks:
    - import_role: 
        name: tosit.tdp.ranger
      vars:
        ranger_jdbc_connector_package: postgresql-jdbc
        realm: TDP
        kadmin_principal: admin/admin
        kadmin_password: admin
        install_properties:
            db_host: "{{ hostvars[groups['postgresql'][0]]['ansible_host']}}:5432"
            db_user: postgres
            db_password: postgres
            DB_FLAVOR: postgres
            db_name: ranger
            audit_store: postgresql # deprecated but keeps the setup.sh script from requesting a solr endpoint
            SQL_CONNECTOR_JAR: /usr/share/java/postgresql-jdbc.jar
      tags: rapb

- hosts: hdfs_nn
  become: yes
  vars:
    - realm: TDP
    - kadmin_principal: admin/admin
    - kadmin_password: admin
    - ranger_admin_password: RangerAdmin123
  tasks:
    - import_role:
        name: tosit.tdp.hadoop
        tasks_from: ranger_hdfs_plugin
      tags: hdfspi

- hosts: yarn_rm
  vars:
    - realm: TDP
    - kadmin_principal: admin/admin
    - kadmin_password: admin
    - ranger_admin_password: RangerAdmin123
    - yarn_site:
        hadoop.zk.address: "{{ hadoop_ha_zookeeper_quorum | trim }}"
        yarn.application.classpath: "$HADOOP_CONF_DIR, {{ hadoop_install_dir }}/share/hadoop/common/*, {{ hadoop_install_dir }}/share/hadoop/common/lib/*, {{ hadoop_install_dir }}/share/hadoop/hdfs/*, {{ hadoop_install_dir }}/share/hadoop/hdfs/lib/*, {{ hadoop_install_dir }}/share/hadoop/yarn/*, {{ hadoop_install_dir }}/share/hadoop/yarn/lib/*"
        yarn.http.policy: HTTPS_ONLY
        yarn.log-aggregation-enable: "true"
        yarn.nodemanager.remote-app-log-dir: "/app-logs"
        yarn.nodemanager.remote-app-log-dir-suffix : "logs"
        yarn.resourcemanager.ha.enabled: "true"
        yarn.resourcemanager.ha.rm-ids: "rm1,rm2"
        yarn.resourcemanager.cluster-id: "mycluster"
        yarn.resourcemanager.hostname.rm1: "{{ groups['yarn_rm'][0] | tosit.tdp.access_fqdn(hostvars) }}"
        yarn.resourcemanager.hostname.rm2: "{{ groups['yarn_rm'][1] | tosit.tdp.access_fqdn(hostvars) }}"
        yarn.resourcemanager.webapp.address.rm1: "{{ groups['yarn_rm'][0] | tosit.tdp.access_fqdn(hostvars) }}:8088"
        yarn.resourcemanager.webapp.address.rm2: "{{ groups['yarn_rm'][1] | tosit.tdp.access_fqdn(hostvars) }}:8088"
        yarn.resourcemanager.webapp.https.address.rm1: "{{ groups['yarn_rm'][0] | tosit.tdp.access_fqdn(hostvars) }}:8090"
        yarn.resourcemanager.webapp.https.address.rm2: "{{ groups['yarn_rm'][1] | tosit.tdp.access_fqdn(hostvars) }}:8090"
        yarn.resourcemanager.webapp.spnego-keytab-file: /etc/security/keytabs/spnego.service.keytab
        yarn.resourcemanager.webapp.spnego-principal: "HTTP/_HOST@{{ realm }}"
        yarn.resourcemanager.keytab: /etc/security/keytabs/rm.service.keytab
        yarn.resourcemanager.principal: "rm/_HOST@{{ realm }}"
        yarn.resourcemanager.system-metrics-publisher.enabled: "true"
        yarn.resourcemanager.recovery.enabled: "true"
        yarn.resourcemanager.store.class: "org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore"
        yarn.nodemanager.local-dirs: /data/yarn/local
        yarn.nodemanager.log-dirs: /data/yarn/logs
        yarn.nodemanager.container-executor.class: org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor
        yarn.nodemanager.linux-container-executor.group: hadoop
        yarn.nodemanager.aux-services: mapreduce_shuffle
        yarn.nodemanager.aux-services.mapreduce_shuffle.class: org.apache.hadoop.mapred.ShuffleHandler
        yarn.nodemanager.address: 0.0.0.0:45454
        yarn.nodemanager.bind-host: 0.0.0.0
        yarn.nodemanager.webapp.address: 0.0.0.0:8042
        yarn.nodemanager.webapp.https.address: 0.0.0.0:8044
        yarn.nodemanager.recovery.enabled: true
        yarn.nodemanager.recovery.dir: "{{ hadoop_yarn_dir }}"
        yarn.nodemanager.resource.cpu-vcores: 8
        yarn.nodemanager.resource.memory-mb: 8192
        yarn.scheduler.minimum-allocation-mb: 1024
        yarn.scheduler.maximum-allocation-mb: 8192
        yarn.nodemanager.principal: "nm/_HOST@{{ realm }}"
        yarn.nodemanager.keytab: /etc/security/keytabs/nm.service.keytab
        yarn.nodemanager.webapp.spnego-keytab-file: /etc/security/keytabs/spnego.service.keytab
        yarn.nodemanager.webapp.spnego-principal: "HTTP/_HOST@{{ realm }}"
        #yarn.nodemanager.vmem-check-enabled: "false"
        yarn.nodemanager.vmem-pmem-ratio: 4
        yarn.timeline-service.enabled: "true"
        yarn.timeline-service.generic-application-history.enabled: "true"
        yarn.timeline-service.hostname: "{{ groups['yarn_ats'][0] | tosit.tdp.access_fqdn(hostvars) }}"
        yarn.timeline-service.address: 0.0.0.0:10200
        yarn.timeline-service.webapp.https.address: "{{ groups['yarn_ats'][0] | tosit.tdp.access_fqdn(hostvars) }}:8190"
        yarn.timeline-service.principal: ats/_HOST@{{ realm }}
        yarn.timeline-service.keytab: /etc/security/keytabs/ats.service.keytab
        # To enable Kerberos on the ATS UI
        yarn.timeline-service.http-authentication.type: kerberos
        yarn.timeline-service.http-authentication.kerberos.principal: HTTP/_HOST@{{ realm }}
        yarn.timeline-service.http-authentication.kerberos.keytab: /etc/security/keytabs/spnego.service.keytab
  become: yes
  tasks:
    - import_role:
        name: tosit.tdp.hadoop
        tasks_from: ranger_yarn_plugin
      tags: yarnpi
